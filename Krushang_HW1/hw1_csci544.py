# -*- coding: utf-8 -*-
"""HW1_CSCI544.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tn2Lzv0nfAmLYcYjjV3A5FVAoSkbom7P
"""
# 
# Commented out IPython magic to ensure Python compatibility.
# %pip install nltk
# %pip install beautifulsoup4
# %pip install contractions
# %pip install bs4 # in case you don't have it installed
# %pip install scikit-learn
import warnings
warnings.filterwarnings("ignore")

import pandas as pd
import numpy as np
import nltk
nltk.download('wordnet')
import re
from bs4 import BeautifulSoup
import contractions
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
from sklearn.model_selection import train_test_split

url= "https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz"

df = pd.read_csv('amazon_reviews_us_Office_Products_v1_00.tsv', sep=r"\t+", usecols=['star_rating', 'review_body'])

df['star_rating'] = df['star_rating'].apply(lambda x: 2 if x in [4,5] else 1)

random_state = 25
class1_samples = df[df['star_rating'] == 1].sample(n=50000, random_state=random_state)
class2_samples = df[df['star_rating'] == 2].sample(n=50000, random_state=random_state)
class1_samples = class1_samples.reset_index(drop=True)
class2_samples = class2_samples.reset_index(drop=True)

final_df = pd.concat([class1_samples, class2_samples], ignore_index=True)
final_df = final_df.reset_index(drop=True)

flenDC = final_df['review_body'].str.len().mean()

def expand_contractions(text):
    if text is None:
        return None
    return contractions.fix(str(text))

final_df['review_body'] = final_df['review_body'].str.lower()

url_pattern = r'https?://\S+|www\.\S+'
html_pattern = r'<.*?>'
non_alpha_pattern = r'[^a-zA-Z\s]'

final_df['review_body'] = final_df['review_body'].str.replace(url_pattern, '', regex=True)
final_df['review_body'] = final_df['review_body'].str.replace(html_pattern, '', regex=True)
final_df['review_body'] = final_df['review_body'].str.replace(non_alpha_pattern, '', regex=True)
final_df['review_body'] = final_df['review_body'].str.replace(r'\s+', ' ', regex=True)
final_df['review_body'] = final_df['review_body'].apply(expand_contractions)

slenDC = final_df['review_body'].str.len().mean()
print(f"{flenDC:.4f},{slenDC:.4f}")

flenPP = final_df['review_body'].str.len().mean()

lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    if text is None:
        return None
    tokens = nltk.word_tokenize(text)
    filtered_tokens = [word for word in tokens if word not in stop_words]
    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]
    return ' '.join(lemmatized_tokens)

final_df['review_body'] = final_df['review_body'].apply(preprocess_text)

slenPP = final_df['review_body'].str.len().mean()
print(f"{flenPP:.4f},{slenPP:.4f}")

train_df, test_df = train_test_split(final_df, test_size=0.2, random_state=random_state)

train_df = train_df.reset_index(drop=True)
test_df = test_df.reset_index(drop=True)

train_labels = train_df['star_rating']
test_labels = test_df['star_rating']

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer(max_features=10000)

tfidf_train_features = tfidf_vectorizer.fit_transform(train_df['review_body'])
tfidf_test_features = tfidf_vectorizer.transform(test_df['review_body'])

from sklearn.feature_extraction.text import CountVectorizer

bow_vectorizer = CountVectorizer(max_features=10000)

bow_train_features = bow_vectorizer.fit_transform(train_df['review_body'])
bow_test_features = bow_vectorizer.transform(test_df['review_body'])

from sklearn.linear_model import Perceptron
from sklearn.metrics import precision_score, recall_score, f1_score

perceptron_tfidf = Perceptron()

perceptron_tfidf.fit(tfidf_train_features, train_labels)

tfidf_predictions = perceptron_tfidf.predict(tfidf_test_features)

precision_tfidf = precision_score(test_labels, tfidf_predictions)
recall_tfidf = recall_score(test_labels, tfidf_predictions)
f1_tfidf = f1_score(test_labels, tfidf_predictions)

print(f'{precision_tfidf:.4f} {recall_tfidf:.4f} {f1_tfidf:.4f}')

perceptron_bow = Perceptron()

perceptron_bow.fit(bow_train_features, train_labels)

bow_predictions = perceptron_bow.predict(bow_test_features)

precision_bow = precision_score(test_labels, bow_predictions)
recall_bow = recall_score(test_labels, bow_predictions)
f1_bow = f1_score(test_labels, bow_predictions)

print(f'{precision_bow:.4f} {recall_bow:.4f} {f1_bow:.4f}')

from sklearn.svm import LinearSVC
from sklearn.metrics import precision_score, recall_score, f1_score

svm_tfidf = LinearSVC(dual=True, random_state=random_state)

svm_tfidf.fit(tfidf_train_features, train_labels)

svm_tfidf_predictions = svm_tfidf.predict(tfidf_test_features)

precision_tfidf = precision_score(test_labels, svm_tfidf_predictions)
recall_tfidf = recall_score(test_labels, svm_tfidf_predictions)
f1_tfidf = f1_score(test_labels, svm_tfidf_predictions)

print(f'{precision_tfidf:.4f} {recall_tfidf:.4f} {f1_tfidf:.4f}')

from sklearn.svm import LinearSVC
from sklearn.metrics import precision_score, recall_score, f1_score

svm_bow = LinearSVC(max_iter=10000, random_state=42)

svm_bow.fit(bow_train_features, train_labels)

svm_bow_predictions = svm_bow.predict(bow_test_features)

precision_bow = precision_score(test_labels, svm_bow_predictions)
recall_bow = recall_score(test_labels, svm_bow_predictions)
f1_bow = f1_score(test_labels, svm_bow_predictions)

print(f'{precision_bow:.4f} {recall_bow:.4f} {f1_bow:.4f}')

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, f1_score

logistic_regression_tfidf = LogisticRegression(max_iter=10000, random_state=42)

logistic_regression_tfidf.fit(tfidf_train_features, train_labels)

logistic_regression_tfidf_predictions = logistic_regression_tfidf.predict(tfidf_test_features)

precision_tfidf = precision_score(test_labels, logistic_regression_tfidf_predictions)
recall_tfidf = recall_score(test_labels, logistic_regression_tfidf_predictions)
f1_tfidf = f1_score(test_labels, logistic_regression_tfidf_predictions)

print(f'{precision_tfidf:.4f} {recall_tfidf:.4f} {f1_tfidf:.4f}')

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score, f1_score

logistic_regression_bow = LogisticRegression(max_iter=10000, random_state=42)

logistic_regression_bow.fit(bow_train_features, train_labels)

logistic_regression_bow_predictions = logistic_regression_bow.predict(bow_test_features)

precision_bow = precision_score(test_labels, logistic_regression_bow_predictions)
recall_bow = recall_score(test_labels, logistic_regression_bow_predictions)
f1_bow = f1_score(test_labels, logistic_regression_bow_predictions)

print(f'{precision_bow:.4f} {recall_bow:.4f} {f1_bow:.4f}')

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import precision_score, recall_score, f1_score

naive_bayes_tfidf = MultinomialNB()

naive_bayes_tfidf.fit(tfidf_train_features, train_labels)

naive_bayes_tfidf_predictions = naive_bayes_tfidf.predict(tfidf_test_features)

precision_tfidf = precision_score(test_labels, naive_bayes_tfidf_predictions)
recall_tfidf = recall_score(test_labels, naive_bayes_tfidf_predictions)
f1_tfidf = f1_score(test_labels, naive_bayes_tfidf_predictions)

print(f'{precision_tfidf:.4f} {recall_tfidf:.4f} {f1_tfidf:.4f}')

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import precision_score, recall_score, f1_score

naive_bayes_bow = MultinomialNB()

naive_bayes_bow.fit(bow_train_features, train_labels)

naive_bayes_bow_predictions = naive_bayes_bow.predict(bow_test_features)

precision_bow = precision_score(test_labels, naive_bayes_bow_predictions)
recall_bow = recall_score(test_labels, naive_bayes_bow_predictions)
f1_bow = f1_score(test_labels, naive_bayes_bow_predictions)

print(f'{precision_bow:.4f} {recall_bow:.4f} {f1_bow:.4f}')
warnings.resetwarnings()
